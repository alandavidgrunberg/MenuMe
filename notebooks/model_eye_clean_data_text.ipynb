{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e496116-dcea-4591-a351-499594410e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries \n",
    "import unidecode \n",
    "import pandas as pd \n",
    "import re \n",
    "import time \n",
    "import nltk \n",
    "import nltk.corpus \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from autocorrect import Speller \n",
    "from bs4 import BeautifulSoup \n",
    "from nltk.corpus import stopwords \n",
    "from nltk import word_tokenize \n",
    "import string \n",
    "#https://towardsdatascience.com/cleaning-preprocessing-text-data-by-building-nlp-pipeline-853148add68a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a0e0c61-6f7f-42b4-b587-1a62709dd994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Users/pornpanthongdee/.pyenv/versions/3.8.13/envs/menu_me/lib/python3.8/site-packages (3.7)\n",
      "Requirement already satisfied: click in /Users/pornpanthongdee/.pyenv/versions/3.8.13/envs/menu_me/lib/python3.8/site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: tqdm in /Users/pornpanthongdee/.pyenv/versions/3.8.13/envs/menu_me/lib/python3.8/site-packages (from nltk) (4.64.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/pornpanthongdee/.pyenv/versions/3.8.13/envs/menu_me/lib/python3.8/site-packages (from nltk) (2022.6.2)\n",
      "Requirement already satisfied: joblib in /Users/pornpanthongdee/.pyenv/versions/3.8.13/envs/menu_me/lib/python3.8/site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: unidecode in /Users/pornpanthongdee/.pyenv/versions/3.8.13/envs/menu_me/lib/python3.8/site-packages (1.3.4)\n",
      "Collecting bs4\n",
      "  Using cached bs4-0.0.1.tar.gz (1.1 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /Users/pornpanthongdee/.pyenv/versions/3.8.13/envs/menu_me/lib/python3.8/site-packages (from bs4) (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/pornpanthongdee/.pyenv/versions/3.8.13/envs/menu_me/lib/python3.8/site-packages (from beautifulsoup4->bs4) (2.3.2.post1)\n",
      "Using legacy 'setup.py install' for bs4, since package 'wheel' is not installed.\n",
      "Installing collected packages: bs4\n",
      "  Running setup.py install for bs4 ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed bs4-0.0.1\n",
      "Collecting autocorrect\n",
      "  Downloading autocorrect-2.6.1.tar.gz (622 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m622.8/622.8 kB\u001b[0m \u001b[31m246.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hUsing legacy 'setup.py install' for autocorrect, since package 'wheel' is not installed.\n",
      "Installing collected packages: autocorrect\n",
      "  Running setup.py install for autocorrect ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed autocorrect-2.6.1\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "!pip install unidecode\n",
    "!pip install bs4\n",
    "!pip install autocorrect "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b3b57f49-a6ac-4d1a-ad0c-4ae0a1a12809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I always wrote this series off as being a comp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1st watched 12/7/2002 - 3 out of 10(Dir-Steve ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This movie was so poorly written and directed ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The most interesting thing about Miryang (Secr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>when i first read about \"berlin am meer\" i did...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  I always wrote this series off as being a comp...      0\n",
       "1  1st watched 12/7/2002 - 3 out of 10(Dir-Steve ...      0\n",
       "2  This movie was so poorly written and directed ...      0\n",
       "3  The most interesting thing about Miryang (Secr...      1\n",
       "4  when i first read about \"berlin am meer\" i did...      0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read Dataset \n",
    "df = pd.read_csv('raw_data/Test.csv')\n",
    "# Show Dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e8080d7a-eb23-4d03-b507-26b759d06955",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_newlines_tabs(text):\n",
    "    \"\"\"\n",
    "    This function will remove all the occurrences of newlines, tabs, and combinations like: \\\\n, \\\\.\n",
    "    \n",
    "    arguments:\n",
    "        input_text: \"text\" of type \"String\". \n",
    "                    \n",
    "    return:\n",
    "        value: \"text\" after removal of newlines, tabs, \\\\n, \\\\ characters.\n",
    "        \n",
    "    Example:\n",
    "    Input : This is her \\\\ first day at this place.\\n Please,\\t Be nice to her.\\\\n\n",
    "    Output : This is her first day at this place. Please, Be nice to her. \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Replacing all the occurrences of \\n,\\\\n,\\t,\\\\ with a space.\n",
    "    Formatted_text = text.replace('\\\\n', ' ').replace('\\n', ' ').replace('\\t',' ').replace('\\\\', ' ').replace('. com', '.com')\n",
    "    return Formatted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ae6eec1a-148e-4344-9da5-8860e29f37b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b993c740-9492-4520-bf87-a781082cacbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"clean_text\"]= None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f1cb4666-c5ce-4819-b94e-141048d59f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text=remove_newlines_tabs(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dd9bfe4d-876d-4155-8e08-fdd1df3128af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_whitespace(text):\n",
    "    \"\"\" This function will remove \n",
    "        extra whitespaces from the text\n",
    "    arguments:\n",
    "        input_text: \"text\" of type \"String\". \n",
    "                    \n",
    "    return:\n",
    "        value: \"text\" after extra whitespaces removed .\n",
    "        \n",
    "    Example:\n",
    "    Input : How   are   you   doing   ?\n",
    "    Output : How are you doing ?     \n",
    "        \n",
    "    \"\"\"\n",
    "    pattern = re.compile(r'\\s+') \n",
    "    Without_whitespace = re.sub(pattern, ' ', text)\n",
    "    # There are some instances where there is no space after '?' & ')', \n",
    "    # So I am replacing these with one space so that It will not consider two words as one token.\n",
    "    text = Without_whitespace.replace('?', ' ? ').replace(')', ') ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c5b0c083-3809-49d7-bcb1-d0f13cda906f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for accented characters removal\n",
    "def accented_characters_removal(text):\n",
    "    # this is a docstring\n",
    "    \"\"\"\n",
    "    The function will remove accented characters from the \n",
    "    text contained within the Dataset.\n",
    "       \n",
    "    arguments:\n",
    "        input_text: \"text\" of type \"String\". \n",
    "                    \n",
    "    return:\n",
    "        value: \"text\" with removed accented characters.\n",
    "        \n",
    "    Example:\n",
    "    Input : Málaga, àéêöhello\n",
    "    Output : Malaga, aeeohello    \n",
    "        \n",
    "    \"\"\"\n",
    "    # Remove accented characters from text using unidecode.\n",
    "    # Unidecode() - It takes unicode data & tries to represent it to ASCII characters. \n",
    "    text = unidecode.unidecode(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "14555bb1-1147-4a6c-ab7d-abc9b4cca506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_casing_text(text):\n",
    "    \n",
    "    \"\"\"\n",
    "    The function will convert text into lower case.\n",
    "    \n",
    "    arguments:\n",
    "         input_text: \"text\" of type \"String\".\n",
    "         \n",
    "    return:\n",
    "         value: text in lowercase\n",
    "         \n",
    "    Example:\n",
    "    Input : The World is Full of Surprises!\n",
    "    Output : the world is full of surprises!\n",
    "    \n",
    "    \"\"\"\n",
    "    # Convert text to lower case\n",
    "    # lower() - It converts all upperase letter of given string to lowercase.\n",
    "    text = text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523b05a2-2866-4e16-aa93-93977979ed44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "547fef56-1aaa-46da-a9e6-326c9042cbf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/74/zq1vl5mj4518hvqv44mrtkd80000gn/T/ipykernel_71720/1731691925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"clean_text\"].iloc[i]= text\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I always wrote this series off as being a comp...</td>\n",
       "      <td>0</td>\n",
       "      <td>i always wrote this series off as being a comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1st watched 12/7/2002 - 3 out of 10(Dir-Steve ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1st watched 12/7/2002 - 3 out of 10(dir-steve ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This movie was so poorly written and directed ...</td>\n",
       "      <td>0</td>\n",
       "      <td>this movie was so poorly written and directed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The most interesting thing about Miryang (Secr...</td>\n",
       "      <td>1</td>\n",
       "      <td>the most interesting thing about miryang (secr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>when i first read about \"berlin am meer\" i did...</td>\n",
       "      <td>0</td>\n",
       "      <td>when i first read about \"berlin am meer\" i did...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>This is the kind of picture John Lassiter woul...</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>A MUST SEE! I saw WHIPPED at a press screening...</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>NBC should be ashamed. I wouldn't allow my chi...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>This movie is a clumsy mishmash of various gho...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>Formula movie about the illegitimate son of a ...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label  \\\n",
       "0     I always wrote this series off as being a comp...      0   \n",
       "1     1st watched 12/7/2002 - 3 out of 10(Dir-Steve ...      0   \n",
       "2     This movie was so poorly written and directed ...      0   \n",
       "3     The most interesting thing about Miryang (Secr...      1   \n",
       "4     when i first read about \"berlin am meer\" i did...      0   \n",
       "...                                                 ...    ...   \n",
       "4995  This is the kind of picture John Lassiter woul...      1   \n",
       "4996  A MUST SEE! I saw WHIPPED at a press screening...      1   \n",
       "4997  NBC should be ashamed. I wouldn't allow my chi...      0   \n",
       "4998  This movie is a clumsy mishmash of various gho...      0   \n",
       "4999  Formula movie about the illegitimate son of a ...      0   \n",
       "\n",
       "                                             clean_text  \n",
       "0     i always wrote this series off as being a comp...  \n",
       "1     1st watched 12/7/2002 - 3 out of 10(dir-steve ...  \n",
       "2     this movie was so poorly written and directed ...  \n",
       "3     the most interesting thing about miryang (secr...  \n",
       "4     when i first read about \"berlin am meer\" i did...  \n",
       "...                                                 ...  \n",
       "4995                                               None  \n",
       "4996                                               None  \n",
       "4997                                               None  \n",
       "4998                                               None  \n",
       "4999                                               None  \n",
       "\n",
       "[5000 rows x 3 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "for i in range(5):\n",
    "    text = df.iloc[i][\"text\"]\n",
    "    text = accented_characters_removal(text)\n",
    "    text = lower_casing_text(text)\n",
    "    # print(text)\n",
    "    text=remove_newlines_tabs(text)\n",
    "    text=remove_whitespace(text)\n",
    "    df[\"clean_text\"].iloc[i]= text\n",
    "    \n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fa13a87a-57ab-4a75-8d62-4332e20fc8f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I always wrote this series off as being a complete stink-fest because Jim Belushi was involved in it, and heavily. But then one day a tragic happenstance occurred. After a White Sox game ended I realized that the remote was all the way on the other side of the room somehow. Now I could have just gotten up and walked across the room to get the remote, or even to the TV to turn the channel. But then why not just get up and walk across the country to watch TV in another state? \"Nuts to that\", I said. So I decided to just hang tight on the couch and take whatever Fate had in store for me. What Fate had in store was an episode of this show, an episode about which I remember very little except that I had once again made a very broad, general sweeping blanket judgment based on zero objective or experiential evidence with nothing whatsoever to back my opinions up with, and once again I was completely right! This show is a total crud-pie! Belushi has all the comedic delivery of a hairy lighthouse foghorn. The women are physically attractive but too Stepford-is to elicit any real feeling from the viewer. There is absolutely no reason to stop yourself from running down to the local TV station with a can of gasoline and a flamethrower and sending every copy of this mutt howling back to hell. <br /><br />Except.. <br /><br />Except for the wonderful comic sty lings of Larry Joe Campbell, America\\'s Greatest Comic Character Actor. This guy plays Belushi\\'s brother-in-law, Andy, and he is gold. How good is he really? Well, aside from being funny, his job is to make Belushi look good. That\\'s like trying to make butt warts look good. But Campbell pulls it off with style. Someone should invent a Nobel Prize in Comic Buffoonery so he can win it every year. Without Larry Joe this show would consist of a slightly vacant looking Courtney Thorne-Smith smacking Belushi over the head with a frying pan while he alternately beats his chest and plays with the straw on the floor of his cage. 5 stars for Larry Joe Campbell designated Comedic Bacon because he improves the flavor of everything he\\'s in!'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bafff1a-6f04-47f0-a337-7dd96bbced4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
