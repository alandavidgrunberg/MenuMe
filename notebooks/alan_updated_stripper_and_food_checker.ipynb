{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ad38301",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_detection_full_response(path):\n",
    "    from google.cloud import vision\n",
    "    import io\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    with io.open(path, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = vision.Image(content=content)\n",
    "\n",
    "    response = client.text_detection(image=image)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3244d3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_language(response):\n",
    "    language = response.text_annotations[0].locale\n",
    "    print('language:')\n",
    "    print(language)\n",
    "    print()\n",
    "    return language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ed8cb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_menu(response):\n",
    "    \n",
    "    # remove these chars from entry\n",
    "    chars_to_remove = '0123456789!\"\\'#$%&()*+,-./:;<=>?@[\\]^_`{|}~♦●★‒…£¡™¢∞§¶•ªº–≠≠œ∑´®†¥¨≤≥÷ç√€'\n",
    "\n",
    "    # remove entry if it exactly matches any of these\n",
    "    drop_exact_words = ['sandwiches','restaurant','menu',\n",
    "                        'restaurant menu','thank you','drinks',\n",
    "                        'appetizer','appetizers','mains','dessert',\n",
    "                        'side','sides','side order','breakfast','lunch'\n",
    "                       'dinner','supper','starter','starters','local',\n",
    "                        'fresh','food','main','your','logo','brand name'\n",
    "                       'monday','tuesday','wednesday','thursday','friday',\n",
    "                       'saturday','sunday']\n",
    "    \n",
    "    # remove these words from entry\n",
    "    words_to_remove = ['menu','restaurant','price','appetizer',\n",
    "                       'appetizers','course','price','extra','extras']\n",
    "\n",
    "    # remove entry if it contains any of these\n",
    "    drop_contain_words = ['tax','consumer','advisory','illness','facebook','instagram']\n",
    "    \n",
    "    # remove entry if it starts with any of these\n",
    "    drop_start_words = ['add','include','includes','including','lorem','with','and',\n",
    "                       'served','serve']\n",
    "    \n",
    "    # drop entry if it contains fewer chars than minimum\n",
    "    min_length = 4\n",
    "    \n",
    "    \n",
    "    text = response.text_annotations[0].description\n",
    "    menu_original = text.split('\\n')\n",
    "    \n",
    "    menu_chars_removed = []\n",
    "    for item in menu_original:\n",
    "        for char in chars_to_remove:\n",
    "            item = item.replace(char,' ')\n",
    "        menu_chars_removed.append(item)\n",
    "        \n",
    "    menu_exact_matches_dropped = []\n",
    "    for item in menu_chars_removed:\n",
    "        if item.lower() in drop_exact_words:\n",
    "            pass\n",
    "        else:\n",
    "            menu_exact_matches_dropped.append(item)\n",
    "        \n",
    "    menu_words_removed = []\n",
    "    for item in menu_exact_matches_dropped:\n",
    "        temporary = []\n",
    "        for word in item.split(' '):\n",
    "            if word.lower() not in words_to_remove:\n",
    "                temporary.append(word)\n",
    "        remaining_words = ' '.join(temporary)\n",
    "        menu_words_removed.append(remaining_words)\n",
    "             \n",
    "    menu_contains_dropped = []\n",
    "    for item in menu_words_removed:\n",
    "        temporary = []\n",
    "        for word in item.split(' '):\n",
    "            if word.lower() in drop_contain_words:\n",
    "                temporary = []\n",
    "                pass\n",
    "            else:\n",
    "                temporary.append(word)\n",
    "        remaining_words = ' '.join(temporary)\n",
    "        menu_contains_dropped.append(remaining_words)\n",
    "\n",
    "    menu_starts_dropped = []\n",
    "    for item in menu_contains_dropped:\n",
    "        temporary = item.split(' ')\n",
    "        if temporary[0].lower() in drop_start_words:\n",
    "            pass\n",
    "        else:\n",
    "            menu_starts_dropped.append(item)\n",
    "    \n",
    "    menu_exact_matches_dropped = []\n",
    "    for item in menu_starts_dropped:\n",
    "        if item.lower() in drop_exact_words:\n",
    "            pass\n",
    "        else:\n",
    "            menu_exact_matches_dropped.append(item)\n",
    "            \n",
    "    bounding_white_space_removed = [item.strip() for item in menu_exact_matches_dropped]\n",
    "    too_short_dropped = [item for item in bounding_white_space_removed if len(item) >= min_length]\n",
    "    \n",
    "    duplicates_dropped = []\n",
    "    for item in too_short_dropped:\n",
    "        if item not in duplicates_dropped:\n",
    "            duplicates_dropped.append(item)\n",
    "\n",
    "    \n",
    "    stripped_menu = duplicates_dropped\n",
    "    \n",
    "    print('original menu:')\n",
    "    print()\n",
    "    print(menu_original)\n",
    "    print()\n",
    "    print('stripped menu:')\n",
    "    print()\n",
    "    print(stripped_menu)\n",
    "    print()\n",
    "    return(stripped_menu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1e73c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimized_image_fetch_and_check(query):\n",
    "    import os\n",
    "    from dotenv import load_dotenv, find_dotenv\n",
    "    from google_images_search import GoogleImagesSearch\n",
    "    from google.cloud import vision\n",
    "\n",
    "    env_path = find_dotenv()\n",
    "    load_dotenv(env_path)\n",
    "    \n",
    "    GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')\n",
    "    GOOGLE_CX = os.getenv('GOOGLE_CX')\n",
    "    \n",
    "    helper_word = 'recipe'\n",
    "    \n",
    "    beverages = ['coca cola', 'cola', 'pepsi','coffee','pepsi cola','bintang','budweiser','red wine', 'mountain dew','coke','screwdriver']\n",
    "\n",
    "    if query.lower() in beverages:\n",
    "        helper_word = 'beverage'\n",
    "    \n",
    "    print(f'searching for {query} ({helper_word})...')\n",
    "    print()\n",
    "\n",
    "    gis = GoogleImagesSearch(GOOGLE_API_KEY,GOOGLE_CX)\n",
    "\n",
    "    if query.lower() in beverages:\n",
    "        helper_word = 'beverage'\n",
    "    \n",
    "    _search_params = {\n",
    "    'q': f'{query} {helper_word}',\n",
    "    'num': 1,\n",
    "    #'imgSize': 'large',\n",
    "    'imgType': 'photo',\n",
    "    'imgColorType': 'color'}\n",
    "    \n",
    "    gis.search(search_params=_search_params)\n",
    "    print('fetching image:')\n",
    "    if len(gis.results()) == 0:\n",
    "        print('no image found, not verified as food.')\n",
    "        print()\n",
    "        return None\n",
    "    \n",
    "    url = gis.results()[0].url\n",
    "    print(url)\n",
    "    print()\n",
    "    \n",
    "    verified_queries = ['cheeseburger','burger','pizza','fried chicken','ice cream sundae','fuyung hai','screwdriver','redbull',\n",
    "                       'loaded baked potato', 'roasted vegetables','strawberry cake']\n",
    "    \n",
    "    if query.lower() in verified_queries:\n",
    "        print(f'{query} already in known foods database, no need to verify!')\n",
    "        print()\n",
    "        return url\n",
    "    \n",
    "    client = vision.ImageAnnotatorClient()\n",
    "    image = vision.Image()\n",
    "    image.source.image_uri = url\n",
    "    \n",
    "    response = client.label_detection(image=image, max_results=1)\n",
    "    label = [lab.description for lab in response.label_annotations]\n",
    "    score = [lab.score for lab in response.label_annotations]\n",
    "    \n",
    "    text_response = client.text_detection(image=image)\n",
    "    texts = text_response.text_annotations\n",
    "    n_chars = 0\n",
    "    if len(texts)>0:\n",
    "        n_chars = len(texts[0].description)\n",
    "    \n",
    "    print('verification filter:')\n",
    "    print('label must be Food, Tableware, Bottle, Beverage can, Liquid, or Water')\n",
    "    print('score must be above .955')\n",
    "    print('number of chars must be below 200')\n",
    "    print()\n",
    "    print(f'label: {label}')\n",
    "    print(f'label score: {score}')\n",
    "    print(f'chars detected: {n_chars}')\n",
    "    print()\n",
    "    \n",
    "    try:\n",
    "        if (label[0] in ['Food','Tableware','Bottle','Beverage can','Liquid','Water']) and score[0] > .955 and n_chars < 200:\n",
    "            print('verified!')\n",
    "            print()\n",
    "            print(url)\n",
    "            print()\n",
    "            return url\n",
    "    except IndexError:\n",
    "        print('label missing, not verified.')\n",
    "        pass\n",
    "    \n",
    "\n",
    "    _search_params = {\n",
    "    'q': f'{query} {helper_word}]',\n",
    "    'num': 3,\n",
    "    #'imgSize': 'large',\n",
    "    'imgType': 'photo',\n",
    "    'imgColorType': 'color',\n",
    "    'safe': 'medium'}\n",
    "        \n",
    "    gis = GoogleImagesSearch(GOOGLE_API_KEY,GOOGLE_CX)\n",
    "    gis.search(search_params=_search_params)\n",
    "    urls = [result.url for result in gis.results()]\n",
    "    print('fetching additional images:')\n",
    "    if len(urls)<=1:\n",
    "        print('no additional images found, not verified.')\n",
    "        return None\n",
    "    urls = urls[1:]\n",
    "    for url in urls:\n",
    "        print(url)\n",
    "    print()\n",
    "    \n",
    "    labels = []\n",
    "    scores = []\n",
    "    char_counts = [] \n",
    "    for url in urls:\n",
    "        \n",
    "        image.source.image_uri = url\n",
    "        response = client.label_detection(image=image, max_results=1)\n",
    "        label = [lab.description for lab in response.label_annotations]\n",
    "        score = [lab.score for lab in response.label_annotations]\n",
    "        labels.append(label)\n",
    "        scores.append(score)\n",
    "        \n",
    "        text_response = client.text_detection(image=image)\n",
    "        texts = text_response.text_annotations\n",
    "        n_chars = 0\n",
    "        if len(texts)>0:\n",
    "            n_chars = len(texts[0].description)\n",
    "        char_counts.append(n_chars)\n",
    "        \n",
    "    print(f'labels: {labels}')\n",
    "    print(f'label scores: {scores}')\n",
    "    print(f'chars detected: {char_counts}')\n",
    "    print()\n",
    "\n",
    "    for label,score,n_chars in zip(labels,scores, char_counts):\n",
    "        try:\n",
    "            if (label[0] in ['Food','Tableware','Bottle','Beverage can','Liquid','Water']) and score[0] > .955 and n_chars < 200:\n",
    "                print('verified!')\n",
    "                print()\n",
    "                print(urls[labels.index(label)])\n",
    "                print()\n",
    "                return urls[labels.index(label)]\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    print('not verified.')\n",
    "    print()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "beaf81e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_text_boxes(response):\n",
    "    \n",
    "    import pandas as pd\n",
    "    \n",
    "    texts = response.text_annotations\n",
    "    language = texts[0].locale\n",
    "\n",
    "    text_list = []\n",
    "    top_left = []\n",
    "    top_right = []\n",
    "    bottom_left = []\n",
    "    bottom_right = []\n",
    "\n",
    "\n",
    "    for text in texts[1:]:\n",
    "        new_text = '''{}'''.format(text.description)\n",
    "        text_list.append(new_text)\n",
    "        \n",
    "        vertices = [tuple((vertex.x, vertex.y)) for vertex in text.bounding_poly.vertices]\n",
    "\n",
    "        new_bounding = vertices\n",
    "\n",
    "        top_left.append(vertices[0])\n",
    "        top_right.append(vertices[1])\n",
    "        bottom_left.append(vertices[3])\n",
    "        bottom_right.append(vertices[2])\n",
    "        \n",
    "    detected_df = pd.DataFrame({\n",
    "        'text': text_list,\n",
    "        'top_left': top_left,\n",
    "        'top_right': top_right,\n",
    "        'bottom_left': bottom_left,\n",
    "        'bottom_right': bottom_right\n",
    "    })\n",
    "\n",
    "    if response.error.message:\n",
    "        raise Exception(\n",
    "            '{}\\nFor more info on error messages, check: '\n",
    "            'https://cloud.google.com/apis/design/errors'.format(\n",
    "                response.error.message))\n",
    "    \n",
    "    if language in ['zh','zh-hk','zh-cn','zh-sg','zh-tw','ja','ko']:\n",
    "        split_chars = []\n",
    "        for item in detected_df.text:\n",
    "            split_chars.append([char for char in item])\n",
    "        \n",
    "        detected_df['text'] = split_chars\n",
    "        detected_df = detected_df.explode('text')\n",
    "    \n",
    "    print(detected_df)\n",
    "    print()\n",
    "        \n",
    "    return detected_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "731dd6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_text_boxes(detected_df, stripped_menu, language='en'):\n",
    "    from itertools import combinations\n",
    "    import pandas as pd\n",
    "    from statistics import stdev\n",
    "    import string\n",
    "\n",
    "    test_menu_df = detected_df\n",
    "    \n",
    "    if language in ['ar','iw','fa','ur','sd','ps','yi']:\n",
    "        box_dict = dict()\n",
    "        for item in stripped_menu:\n",
    "            box_dict[item] = None\n",
    "        print(box_dict)\n",
    "        print()\n",
    "        return box_dict\n",
    "    \n",
    "    if language in ['zh','zh-hk','zh-cn','zh-sg','zh-tw','ja','ko'] and len(detected_df)>225:\n",
    "        box_dict = dict()\n",
    "        for item in stripped_menu:\n",
    "            box_dict[item] = None\n",
    "        print(box_dict)\n",
    "        print()\n",
    "        return box_dict\n",
    "\n",
    "    split_keys = []\n",
    "    if language in ['zh','zh-hk','zh-cn','zh-sg','zh-tw']:\n",
    "        for item in stripped_menu:\n",
    "            split_keys.append([char for char in item])\n",
    "            \n",
    "    else:\n",
    "        for item in stripped_menu:\n",
    "            split_keys.append(item.split())\n",
    "\n",
    "    temp_dfs = []\n",
    "    for key_set in split_keys:\n",
    "        temp_df = pd.DataFrame()\n",
    "        for key in key_set:\n",
    "            mask = test_menu_df['text'] == key\n",
    "            temp_df = pd.concat([temp_df, test_menu_df[mask]])\n",
    "            temp_df = temp_df.drop_duplicates()\n",
    "        temp_df['position'] = temp_df['bottom_left'] \n",
    "\n",
    "        word_positions = list(zip(temp_df.text, temp_df.position))\n",
    "        combos = []\n",
    "\n",
    "        for combo in list(combinations(word_positions, len(key_set))): \n",
    "            text_portion = [pair[0] for pair in combo]\n",
    "            if len(set(text_portion)) == len(key_set):\n",
    "                combos.append(combo)\n",
    "        calc_df = pd.DataFrame(combos)\n",
    "\n",
    "        position_stds = []\n",
    "        for combo in combos:\n",
    "            position = [pair[1] for pair in combo]\n",
    "            if len(position) >= 2:\n",
    "                calc_nums = [pair[1] for pair in position]\n",
    "                position_stds.append(stdev(calc_nums))\n",
    "            else:\n",
    "                position_stds.append(0)\n",
    "        calc_df['position_stds'] = position_stds\n",
    "        calc_df = calc_df.sort_values(by=['position_stds'])\n",
    "\n",
    "        if len(calc_df) > 0:\n",
    "            calc_df = calc_df.iloc[[0]]\n",
    "\n",
    "        keep = []\n",
    "        keep_text = []\n",
    "        keep_pos = []\n",
    "        for column in calc_df:\n",
    "            if column != 'position_stds':\n",
    "                keep.append(calc_df[column].to_string(index=False))\n",
    "        for item in keep:\n",
    "            pair = item.split(', ')\n",
    "            temp_text = [char for char in pair[0] if char not in '[](),']\n",
    "            temp_pos = [char for char in pair[1:]]\n",
    "            temp_pos = str(temp_pos)\n",
    "            temp_pos = [char for char in temp_pos if char in string.digits or char not in string.punctuation]\n",
    "            temp_text = ''.join(temp_text)\n",
    "            temp_pos = ''.join(temp_pos)\n",
    "            temp_pos = temp_pos.split(' ')\n",
    "            temp_pos = [int(n) for n in temp_pos]\n",
    "            temp_pos = tuple(temp_pos)\n",
    "\n",
    "            keep_text.append(''.join(temp_text))\n",
    "            keep_pos.append(temp_pos)\n",
    "\n",
    "        merge_df = pd.DataFrame()\n",
    "        for text,pos in zip(keep_text,keep_pos):\n",
    "            merge_df = pd.concat([merge_df, pd.DataFrame({'text': [text],\n",
    "                                    'top_left': [None],\n",
    "                                    'top_right': [None],\n",
    "                                    'bottom_left': [None],\n",
    "                                    'bottom_right': [None],\n",
    "                                    'position': [pos]})], ignore_index=False)\n",
    "        temp_df = pd.concat([temp_df,merge_df],ignore_index=False)\n",
    "        if None in temp_df['top_left'].values:\n",
    "            temp_df = temp_df.loc[temp_df.duplicated(subset='position', keep=False)]\n",
    "        temp_df = temp_df.dropna()\n",
    "\n",
    "        for index in temp_df.index:\n",
    "            if index in test_menu_df.index:\n",
    "                test_menu_df = test_menu_df.drop(index)\n",
    "        temp_dfs.append(temp_df)\n",
    "        \n",
    "    box_dict = {}\n",
    "\n",
    "    for i, item in enumerate(stripped_menu):\n",
    "        try:\n",
    "            box_dict[item] = [temp_dfs[i].iloc[0]['top_left'],\n",
    "                     temp_dfs[i].iloc[-1]['bottom_right']]\n",
    "        except IndexError:\n",
    "            pass\n",
    "    \n",
    "    print(box_dict)\n",
    "    return box_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "634e7d98-dcad-48f4-80d2-2a908954a8da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hand-tossed-salad-large-small'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coord_dict = {'HAND TOSSED SALAD Large Small': [(35, 160), (334, 174)]}\n",
    "list(coord_dict.keys())[0].replace(\" \", \"-\").lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c4fb8abc-4f6b-43c7-b0f3-0357bfd80240",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_text_boxes(path, coord_dict, count):\n",
    "    import io\n",
    "    from matplotlib import pyplot as plt\n",
    "    from matplotlib import patches as pch\n",
    "    \n",
    "    plt.figure(figsize=(20,10))\n",
    "    a = plt.imread(path)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(a)\n",
    "    \n",
    "    \n",
    "    for value in coord_dict.values():\n",
    "        plt.scatter(x = value[0][0], y = value[0][1], alpha=.6, marker =\"*\", c='red', edgecolors='blue', s=500)\n",
    "    \n",
    "    \n",
    "    unique_name = path.split('/')[-1].split('.')[0]\n",
    "    base_url = \"../raw_data/menu_box\"\n",
    "    item_name = list(coord_dict.keys())[0].replace(\" \", \"-\").lower()\n",
    "    plt.savefig(f\"{base_url}/{count}_{unique_name}_{item_name}.png\")\n",
    "\n",
    "# path = '../raw_data/all_menus/english_menu_10.jpg'\n",
    "# coord_dict = {'HAND TOSSED SALAD Large Small': [(35, 160), (334, 174)]}\n",
    "# show_text_boxes(path, coord_dict, count=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6115d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def show_text_boxes(path, coord_dict):\n",
    "#     import io\n",
    "#     from matplotlib import pyplot as plt\n",
    "#     from matplotlib import patches as pch\n",
    "    \n",
    "    \n",
    "#     a = plt.imread(path)\n",
    "#     fig, ax = plt.subplots(1)\n",
    "#     plt.figure(figsize=(20,10))\n",
    "#     ax.imshow(a)\n",
    "    \n",
    "#     for value in coord_dict.values():\n",
    "#         ax.scatter(x = value[0][0], y = value[0][1], alpha=.33, marker =\"*\", c='red', edgecolors='blue', s=100)\n",
    "\n",
    "# path = '../raw_data/all_menus/english_menu_10.jpg'\n",
    "# coord_dict = {'HAND TOSSED SALAD Large Small': [(35, 160), (334, 174)]}\n",
    "# show_text_boxes(path, coord_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f26ee0",
   "metadata": {},
   "source": [
    "# front-end/back-end text box drawer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3be4f211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "language:\n",
      "zh\n",
      "\n",
      "original menu:\n",
      "\n",
      "['休闲至尊堡', '招牌咖喱 力', '♦咖喱鸡扒/猪扒饭', '咖喱牛肉饭', '●咖喱牛腩饭', '咖喱肥牛饭', \"'咖喱海鲜饭\", '咖喱滑鸡饭', '榨菜肉丝汤面', '鲜虾云吞', '●番茄肥牛汤河粉', '香辣牛肉面方', '雪菜肉丝面', '咖喱海鲜面丿', '酱香牛腩面', '鲜虾云吞面', '肠仔/火腿/烟肉煎蛋', '以上可配米粉/河粉/公仔面/意粉', '改乌冬面/车仔面加收3元', '粥类', '瑶柱鸡皇粥', '冬菇滑鸡粥', '皮蛋瘦肉粥', '窝蛋牛肉粥', '明火白粥', '人气出品', '新品推出', '需要时长约25分钟,敬请留意!', '带有辛辣,敬请留意!', '烫粉面类', '28', '35', '35', '30', '32', '30', '18', '23', '20', '20', '15', '20', '23', '23', '18', '15', '13', '13', '15', 'LO', '5', '5335', '至尊空食', '中式饭类', '意', '★台式卤肉饭', '25', '●经典意大利', '至尊鲍鱼鸡饭', '32', '米兰辣i', '★ 葡式咸猪手饭', '28', '三杯鸡饭', '28', '咖喱海鲜', '水煮肥牛饭', '32', '鲜茄牛柳', '白果支竹猪肚饭', '28', '26', '卡邦尼灯', '金菇肥牛饭', '番茄牛肉饭', '法式鸡皇饭', '28', '忌廉蛋汁', '25', '20', '拿破仑', '鱼香茄子饭', '韭黄滑蛋饭', '23', '加5元热', '虾仁滑蛋饭', '28', '叉烧滑蛋饭', '23', '生炒排骨饭', '28', '姜葱白切鸡饭', '30', '手撕鸡饭', '30', '蜜汁叉烧饭', '26', '腊味煲', '香草茄汁鸡扒/鸡扒饭 30', '豉汁拌', '鲜菇牛肉/排骨饭', '30', '榨菜片', '凉瓜牛肉/肉片饭', '25', '萝卜牛腩饭', '●黑椒', '32', '支竹牛腩饭', '32', '榄菜', '酱爆猪颈肉饭', '25', '冬菇', '麻婆豆腐饭 炒', '23', '鱼干', '以上出品送老火汤+5元配炖汤', '加5元送热饮1杯,加7元送冻饮1杯', '咸鱼', '蛋包饭', '蜜汁', '烤', '咖喱海鲜蛋包饭', '28', '虾仁瑶柱蛋包饭', '32', '日式鳗鱼蛋包饭', '32', '温馨提示:', '1、净饮每位收费8元', '12、顾客如在下列情况下打包,本餐厅将收取', 'B.净粉面、白饭、白粥的外卖。(注:玉', '3、饭类配送例汤,送完即止。', '4、30元以上可送外卖,限两公里以内。']\n",
      "\n",
      "stripped menu:\n",
      "\n",
      "['休闲至尊堡', '招牌咖喱 力', '咖喱鸡扒 猪扒饭', '咖喱牛肉饭', '咖喱牛腩饭', '咖喱肥牛饭', '咖喱海鲜饭', '咖喱滑鸡饭', '榨菜肉丝汤面', '鲜虾云吞', '番茄肥牛汤河粉', '香辣牛肉面方', '雪菜肉丝面', '咖喱海鲜面丿', '酱香牛腩面', '鲜虾云吞面', '肠仔 火腿 烟肉煎蛋', '以上可配米粉 河粉 公仔面 意粉', '改乌冬面 车仔面加收 元', '瑶柱鸡皇粥', '冬菇滑鸡粥', '皮蛋瘦肉粥', '窝蛋牛肉粥', '明火白粥', '人气出品', '新品推出', '需要时长约  分钟 敬请留意', '带有辛辣 敬请留意', '烫粉面类', '至尊空食', '中式饭类', '台式卤肉饭', '经典意大利', '至尊鲍鱼鸡饭', '米兰辣i', '葡式咸猪手饭', '三杯鸡饭', '咖喱海鲜', '水煮肥牛饭', '鲜茄牛柳', '白果支竹猪肚饭', '卡邦尼灯', '金菇肥牛饭', '番茄牛肉饭', '法式鸡皇饭', '忌廉蛋汁', '鱼香茄子饭', '韭黄滑蛋饭', '加 元热', '虾仁滑蛋饭', '叉烧滑蛋饭', '生炒排骨饭', '姜葱白切鸡饭', '手撕鸡饭', '蜜汁叉烧饭', '香草茄汁鸡扒 鸡扒饭', '鲜菇牛肉 排骨饭', '凉瓜牛肉 肉片饭', '萝卜牛腩饭', '支竹牛腩饭', '酱爆猪颈肉饭', '麻婆豆腐饭 炒', '以上出品送老火汤  元配炖汤', '加 元送热饮 杯 加 元送冻饮 杯', '咖喱海鲜蛋包饭', '虾仁瑶柱蛋包饭', '日式鳗鱼蛋包饭', '温馨提示', '、净饮每位收费 元', '、顾客如在下列情况下打包 本餐厅将收取', 'B 净粉面、白饭、白粥的外卖。 注 玉', '、饭类配送例汤 送完即止。', '、  元以上可送外卖 限两公里以内。']\n",
      "\n",
      "    text     top_left    top_right  bottom_left bottom_right\n",
      "0      休    (303, 61)    (360, 58)    (304, 80)    (361, 77)\n",
      "0      闲    (303, 61)    (360, 58)    (304, 80)    (361, 77)\n",
      "1      至    (374, 58)    (429, 55)    (375, 76)    (430, 73)\n",
      "1      尊    (374, 58)    (429, 55)    (375, 76)    (430, 73)\n",
      "2      堡    (441, 54)    (466, 53)    (442, 72)    (467, 71)\n",
      "..   ...          ...          ...          ...          ...\n",
      "405    公  (830, 1237)  (874, 1237)  (830, 1261)  (874, 1261)\n",
      "405    里  (830, 1237)  (874, 1237)  (830, 1261)  (874, 1261)\n",
      "406    以  (879, 1238)  (920, 1238)  (879, 1261)  (920, 1261)\n",
      "406    内  (879, 1238)  (920, 1238)  (879, 1261)  (920, 1261)\n",
      "407    。  (926, 1238)  (933, 1238)  (926, 1261)  (933, 1261)\n",
      "\n",
      "[637 rows x 5 columns]\n",
      "\n",
      "{'休闲至尊堡': None, '招牌咖喱 力': None, '咖喱鸡扒 猪扒饭': None, '咖喱牛肉饭': None, '咖喱牛腩饭': None, '咖喱肥牛饭': None, '咖喱海鲜饭': None, '咖喱滑鸡饭': None, '榨菜肉丝汤面': None, '鲜虾云吞': None, '番茄肥牛汤河粉': None, '香辣牛肉面方': None, '雪菜肉丝面': None, '咖喱海鲜面丿': None, '酱香牛腩面': None, '鲜虾云吞面': None, '肠仔 火腿 烟肉煎蛋': None, '以上可配米粉 河粉 公仔面 意粉': None, '改乌冬面 车仔面加收 元': None, '瑶柱鸡皇粥': None, '冬菇滑鸡粥': None, '皮蛋瘦肉粥': None, '窝蛋牛肉粥': None, '明火白粥': None, '人气出品': None, '新品推出': None, '需要时长约  分钟 敬请留意': None, '带有辛辣 敬请留意': None, '烫粉面类': None, '至尊空食': None, '中式饭类': None, '台式卤肉饭': None, '经典意大利': None, '至尊鲍鱼鸡饭': None, '米兰辣i': None, '葡式咸猪手饭': None, '三杯鸡饭': None, '咖喱海鲜': None, '水煮肥牛饭': None, '鲜茄牛柳': None, '白果支竹猪肚饭': None, '卡邦尼灯': None, '金菇肥牛饭': None, '番茄牛肉饭': None, '法式鸡皇饭': None, '忌廉蛋汁': None, '鱼香茄子饭': None, '韭黄滑蛋饭': None, '加 元热': None, '虾仁滑蛋饭': None, '叉烧滑蛋饭': None, '生炒排骨饭': None, '姜葱白切鸡饭': None, '手撕鸡饭': None, '蜜汁叉烧饭': None, '香草茄汁鸡扒 鸡扒饭': None, '鲜菇牛肉 排骨饭': None, '凉瓜牛肉 肉片饭': None, '萝卜牛腩饭': None, '支竹牛腩饭': None, '酱爆猪颈肉饭': None, '麻婆豆腐饭 炒': None, '以上出品送老火汤  元配炖汤': None, '加 元送热饮 杯 加 元送冻饮 杯': None, '咖喱海鲜蛋包饭': None, '虾仁瑶柱蛋包饭': None, '日式鳗鱼蛋包饭': None, '温馨提示': None, '、净饮每位收费 元': None, '、顾客如在下列情况下打包 本餐厅将收取': None, 'B 净粉面、白饭、白粥的外卖。 注 玉': None, '、饭类配送例汤 送完即止。': None, '、  元以上可送外卖 限两公里以内。': None}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# back end\n",
    "path = '../raw_data/all_menus/chinese_menu_1.png'\n",
    "response = text_detection_full_response(path)\n",
    "language = get_language(response)\n",
    "stripped_menu = strip_menu(response)\n",
    "detected_df = detect_text_boxes(response)\n",
    "box_dict = map_text_boxes(detected_df, stripped_menu, language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9659fddd-aae5-495b-b6d5-0f04b4867974",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../raw_data/all_menus/indo_menu_1.png'\n",
    "\n",
    "unique_name = path.split('/')[-1].split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "57d15c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No box founded\n"
     ]
    }
   ],
   "source": [
    "# %%timeit\n",
    "# front end\n",
    "# path = '../raw_data/all_menus/indo_menu_1.png'\n",
    "\n",
    "# gets box_dict from api call\n",
    "\n",
    "# if no coords found in box_dict, skip menu boxing...\n",
    "# if all(element == None for element in box_dict.values()):\n",
    "   \n",
    "#     # # and just fetch/check food pics\n",
    "#     # for key in box_dict.keys():\n",
    "#     #     image_url = optimized_image_fetch_and_check(key)\n",
    "#     print(\"No boxes found\")\n",
    "\n",
    "# if box_dict does contain coords...\n",
    "if not all(element == None for element in box_dict.values()):\n",
    "    count = 0\n",
    "    # looks for food image for each item in box_dict:\n",
    "    for key,value in box_dict.items():\n",
    "\n",
    "            # show menu with that item boxed\n",
    "        coord_dict = {key:value}\n",
    "        show_text_boxes(path, coord_dict, count)\n",
    "\n",
    "            # add item to verified_box_dict\n",
    "        verified_box_dict[key] = value\n",
    "        count += 1\n",
    "else:\n",
    "    print(\"No box founded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bc27e9-d382-4152-86d3-18ca4bc91ba9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
